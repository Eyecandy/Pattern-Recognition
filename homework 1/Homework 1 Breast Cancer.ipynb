{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 Breast Cancer\n",
    "\n",
    "The data in this homework is from http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29\n",
    "\n",
    "You can read what each column means from the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) (0)First write a function that separate the data into 20% test and 80% train. Hint: use np.random.seed to fix random number generator.\n",
    "\n",
    "- What could happen if you just pick last 20%?\n",
    "- Why do we need to randomize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "def separateData():\n",
    "    np.random.seed(1)\n",
    "    data = 'breast-cancer-wisconsin.data.txt'\n",
    "    lst = open(data,'r').read().split('\\n')\n",
    "    lengthOfList = len(lst)-1\n",
    "    numberOfTrainedIndexes = int(lengthOfList*0.8)\n",
    "    a = np.arange(lengthOfList)\n",
    "    np.random.shuffle(a)\n",
    "    trainedDataIndexes = a[:numberOfTrainedIndexes]\n",
    "    testDataIndexes =  a[numberOfTrainedIndexes:]\n",
    "    trainedData = []\n",
    "    testData = []\n",
    "    for i in trainedDataIndexes:\n",
    "        elt = lst[i].split(',')[1:]\n",
    "        trainedData.append(elt)\n",
    "   \n",
    "    for j in testDataIndexes:\n",
    "        elt = lst[j].split(',')[1:]\n",
    "        testData.append(elt)\n",
    "    return trainedData,testData\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) (0) There are many features in the data. Tell me one from the data set that you should NOT use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) (100) Build a Bayes Classifier for figuring out whether the tumor is cancerour or benign. Train on 80% and test on the 20%.\n",
    "- Justify the prior you use.\n",
    "- How many do you get correctly on test dataset?\n",
    "- Do you think the the number we got correctly on the test dataset is the thing we should optimize? Why and why not? (Exercise your common sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971428571429\n"
     ]
    }
   ],
   "source": [
    "def addToDic(TCindex,i,cls,dic):\n",
    "    idxTumorCase= int(TCindex)\n",
    "    if cls == 2:\n",
    "        dic[i][idxTumorCase-1] += 1\n",
    "    else:\n",
    "        dic[i+9][idxTumorCase-1] += 1\n",
    "        \n",
    "def CountBenignAndMalignant(cm,cb,cls):\n",
    "        if cls == 2:\n",
    "            cb +=1\n",
    "        else:\n",
    "            cm +=1\n",
    "        return cm,cb\n",
    "\n",
    "def count():\n",
    "    trainedData = separateData()[0]\n",
    "    dic = {}\n",
    "    for i in range(9*2):\n",
    "        dic[i] = [1,1,1,1,1,1,1,1,1,1]\n",
    "    cb = 0\n",
    "    cm = 0\n",
    "    for tumorCase in trainedData:\n",
    "        cls = int(tumorCase[-1])\n",
    "        cm,cb = CountBenignAndMalignant(cm,cb,cls)\n",
    "        featuresOfTumorCase = tumorCase[:-1]\n",
    "        for i in range(len(tumorCase)-1):\n",
    "            if tumorCase[i] != '?':\n",
    "                addToDic(tumorCase[i],i,cls,dic)\n",
    "  \n",
    "    return (cb,cm,dic)\n",
    "\n",
    "def makeValueInDicToProb():\n",
    "    cb = count()[0]\n",
    "    cm = count()[1]\n",
    "    dic = count()[2]\n",
    "    for i in range(18):\n",
    "        for j in range(len((dic[i]))):\n",
    "            if i <= 8:\n",
    "                dic[i][j] = dic[i][j]/float(cb)\n",
    "            else:\n",
    "                dic[i][j] = dic[i][j]/float(cm) \n",
    "    return dic\n",
    "         \n",
    "\n",
    "def testData():\n",
    "    dic = makeValueInDicToProb()\n",
    "    tstData = separateData()[1]\n",
    "    pt = 559/float(699)\n",
    "    x = 0\n",
    "    xNot = 0\n",
    "    count2 = 0\n",
    "    cc = 0\n",
    "    for i in tstData:\n",
    "        for j in range(18):\n",
    "            \n",
    "            if j <= 8:\n",
    "                if i[j] == '?':\n",
    "                    continue\n",
    "                x += abs(np.log(dic[j][int(i[j])-1]))\n",
    "            else:\n",
    "                if i[j-9] == '?':\n",
    "                    continue\n",
    "                xNot += abs(np.log(dic[j][int(i[j-9])-1]))\n",
    "        evidenceTerm = x+xNot\n",
    "        t = x/float(evidenceTerm)\n",
    "       \n",
    "        if t <= 0.5 and int(i[-1]) ==2:\n",
    "            cc +=1\n",
    "        if t >= 0.5 and int(i[-1]) == 4:\n",
    "            cc+=1\n",
    "            \n",
    "        x = 0\n",
    "        xNot =0\n",
    "    print cc/float(len(tstData))\n",
    "          \n",
    "        \n",
    "                              \n",
    "testData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) (Bonus) Try to do something different from what you did in 3) using your original idea. Report what you did even if it is worse than what you did in 3. If possible report why it works better/worse.\n",
    "\n",
    "Do not lookup the paper/other method just yet. I want you to develop the gut feeling in data analysis.\n",
    "\n",
    "Grading will be on scale of (meh 1%, OK? 3%, Hmm interesting 5%, Wow 10%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
